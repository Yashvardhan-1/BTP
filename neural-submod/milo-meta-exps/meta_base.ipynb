{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0d5ec5a150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "import pickle\n",
    "import random\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:4\" # change the available gpu number\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_fraction = 0.1\n",
    "num_runs = 1\n",
    "epochs = 40\n",
    "# model_name = \"LeNet\"\n",
    "model_name = \"resnet18\"\n",
    "submod_func = \"facility-location\"\n",
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LeNet_model import LeNet\n",
    "from models.resent_models import get_resent101_model, get_resent18_model\n",
    "from models.utils import RandomSubsetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "fullset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainset = fullset\n",
    "\n",
    "validation_set_fraction = 0.1\n",
    "num_fulltrn = len(fullset)\n",
    "num_val = int(num_fulltrn * validation_set_fraction)\n",
    "num_trn = num_fulltrn - num_val\n",
    "trainset, valset = random_split(fullset, [num_trn, num_val], generator=torch.Generator().manual_seed(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "val_dataloader = DataLoader(valset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sampler = RandomSubsetSampler(valset, 64)\n",
    "subset_dataloader = DataLoader(valset, sampler=subset_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [3:06:08<00:00, 111.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if model_name==\"LeNet\":\n",
    "    model = LeNet()\n",
    "elif model_name==\"resnet18\":\n",
    "    model = get_resent18_model()\n",
    "elif  model_name==\"resnet101\":\n",
    "    model = get_resent101_model()\n",
    "\n",
    "model = model.to(device)\n",
    "acc_list = []\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn_meta = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "start_time = time.time()\n",
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Train loop\n",
    "    for images, labels in train_dataloader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if model_name==\"LeNet\":\n",
    "            meta_net = LeNet()\n",
    "        elif model_name==\"resnet18\":\n",
    "            meta_net = get_resent18_model()\n",
    "        elif  model_name==\"resnet101\":\n",
    "            meta_net = get_resent101_model()\n",
    "        \n",
    "        meta_net.load_state_dict(model.state_dict())\n",
    "        meta_net = meta_net.to(device)\n",
    "\n",
    "        optimizer_meta = torch.optim.Adam(meta_net.parameters())\n",
    "\n",
    "        meta_net.train()\n",
    "        \n",
    "        y_f_hat = meta_net(images)#predictions\n",
    "        cost = loss_fn_meta(y_f_hat, labels)#normal loss\n",
    "        eps = torch.zeros(cost.size(), requires_grad=True).to(device)\n",
    "        l_f_meta = torch.sum(cost*eps)\n",
    "\n",
    "        optimizer_meta.zero_grad()\n",
    "        eps.retain_grad()\n",
    "        l_f_meta.backward()\n",
    "        optimizer_meta.step()\n",
    "\n",
    "        meta_net.eval()\n",
    "\n",
    "        val_images, val_labels = next(iter(subset_dataloader))\n",
    "        val_images = val_images.to(device)\n",
    "        val_labels = val_labels.to(device)\n",
    "\n",
    "        y_g_hat = meta_net(val_images)\n",
    "        l_g_meta = loss_fn(y_g_hat, val_labels)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            optimizer_meta.zero_grad()\n",
    "            l_g_meta.backward()\n",
    "            grad_eps = eps.grad\n",
    "        \n",
    "        w_tilde = torch.clamp(grad_eps, min=0)\n",
    "        norm_c = torch.sum(w_tilde)\n",
    "\n",
    "        if norm_c != 0:\n",
    "            w = w_tilde / norm_c\n",
    "        else:\n",
    "            w = w_tilde\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn_meta(outputs, labels)\n",
    "        loss = torch.sum(loss*w)\n",
    "        \n",
    "        # Backward pass and update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    acc_list.append(accuracy)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list = [0.4613, 0.5754, 0.5813, 0.6684, 0.6515, 0.6894, 0.6966, 0.7163, 0.7201, 0.7262, 0.7355, 0.7433, 0.7465, 0.7435, 0.7573, 0.7539, 0.7544, 0.7681, 0.7739, 0.7688, 0.7673, 0.772, 0.7648, 0.7867, 0.7549, 0.7883, 0.7817, 0.7869, 0.7787, 0.7848, 0.7883, 0.7399, 0.7802, 0.7901, 0.7875, 0.793, 0.7937, 0.7933, 0.7999, 0.8001, 0.8016, 0.7997, 0.7915, 0.8033, 0.8049, 0.719, 0.8017, 0.8073, 0.7914, 0.7994, 0.8051, 0.8071, 0.8098, 0.8103, 0.7994, 0.8145, 0.8101, 0.8143, 0.8063, 0.811, 0.8019, 0.8001, 0.8129, 0.807, 0.8105, 0.8131, 0.8051, 0.8157, 0.8053, 0.8095, 0.8119, 0.8039, 0.813, 0.8057, 0.8044, 0.8067, 0.8114, 0.8088, 0.8091, 0.8146, 0.8067, 0.8149, 0.8093, 0.808, 0.8135, 0.8165, 0.8112, 0.7998, 0.8188, 0.8088, 0.8122, 0.8095, 0.8102, 0.8172, 0.8106, 0.7577, 0.8163, 0.8168, 0.8158, 0.8197]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-milo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
