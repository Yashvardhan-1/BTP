{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f793c2392b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "import pickle\n",
    "import random\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:3\" # change the available gpu number\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_fraction = 0.1\n",
    "num_runs = 1\n",
    "epochs = 40\n",
    "# model_name = \"LeNet\"\n",
    "model_name = \"resnet18\"\n",
    "submod_func = \"facility-location\"\n",
    "data_dir = \"../data\"\n",
    "milo_sub_base_dir = \"../data/milo-data-gen/cifar10-dino-cls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.LeNet_model import LeNet\n",
    "from models.resent_models import get_resent101_model, get_resent18_model\n",
    "from models.utils import SubDataset, RandomSubsetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 datasets\n",
    "trainset = datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)\n",
    "\n",
    "split_ratio = 0.9\n",
    "\n",
    "n_samples = len(test_dataset)\n",
    "n_test = int(n_samples * split_ratio)\n",
    "n_val = n_samples - n_test\n",
    "testset, valset = random_split(test_dataset, [n_test, n_val])\n",
    "\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "val_dataloader = DataLoader(valset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sampler = RandomSubsetSampler(valset, 64)\n",
    "meta_dataloader = DataLoader(valset, sampler=subset_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submod_func = \"facility-location\"\n",
    "metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "class_data = []\n",
    "subset_fraction = 0.3\n",
    "for i in range(num_classes):\n",
    "    with open(f\"{milo_sub_base_dir}/SGE-{metric}/{submod_func}/class-data-{subset_fraction}/class_{i}.pkl\", \"rb\") as f:\n",
    "        S = pickle.load(f)\n",
    "        class_data.append(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sets = len(class_data[0])\n",
    "data = []\n",
    "for i in range(num_sets):\n",
    "    S = []\n",
    "    for j in range(num_classes):\n",
    "        S.extend(class_data[j][i])\n",
    "    data.append(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:01<00:00, 77.47it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 78.86it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.25it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.32it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.53it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.96it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.44it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.26it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 74.22it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.05it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.62it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.83it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.73it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.14it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.70it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.42it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 75.08it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.88it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 79.70it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.25it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.65it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.74it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.14it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.49it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.45it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.11it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.29it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.17it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.97it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 79.02it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.28it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 78.28it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 73.71it/s]\n",
      "100%|██████████| 141/141 [00:02<00:00, 69.45it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 77.30it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.09it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 80.80it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 81.20it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 77.80it/s]\n",
      "100%|██████████| 141/141 [00:01<00:00, 77.37it/s]\n",
      "100%|██████████| 40/40 [28:05<00:00, 42.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define Model\n",
    "if model_name==\"LeNet\":\n",
    "    model = LeNet()\n",
    "elif model_name==\"resnet18\":\n",
    "    model = get_resent18_model()\n",
    "elif  model_name==\"resnet101\":\n",
    "    model = get_resent101_model()\n",
    "\n",
    "model = model.to(device)\n",
    "acc_list = []\n",
    "R=1\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn_meta = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "start_time = time.time()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    if epoch%R==0:\n",
    "        sub_dataset = SubDataset(indices=data[epoch//R], dataset=trainset)\n",
    "        subset_train_dataloader = DataLoader(sub_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    for images, labels in subset_train_dataloader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if model_name==\"LeNet\":\n",
    "            meta_net = LeNet()\n",
    "        elif model_name==\"resnet18\":\n",
    "            meta_net = get_resent18_model()\n",
    "        elif  model_name==\"resnet101\":\n",
    "            meta_net = get_resent101_model()\n",
    "        \n",
    "        meta_net.load_state_dict(model.state_dict())\n",
    "        meta_net = meta_net.to(device)\n",
    "        optimizer_meta = torch.optim.Adam(meta_net.parameters())\n",
    "\n",
    "        meta_net.train()\n",
    "        \n",
    "        y_f_hat = meta_net(images)\n",
    "        cost = loss_fn_meta(y_f_hat, labels)\n",
    "        eps = torch.zeros(cost.size(), requires_grad=True).to(device)\n",
    "        l_f_meta = torch.sum(cost*eps) #f i,e\n",
    "\n",
    "        # meta_net.zero_grad()\n",
    "        optimizer_meta.zero_grad()\n",
    "        eps.retain_grad()\n",
    "        l_f_meta.backward()\n",
    "        optimizer_meta.step()\n",
    "\n",
    "        meta_net.eval()\n",
    "        \n",
    "        val_images, val_labels = next(iter(meta_dataloader))\n",
    "        val_images = val_images.to(device)\n",
    "        val_labels = val_labels.to(device)\n",
    "\n",
    "        y_g_hat = meta_net(val_images)\n",
    "        l_g_meta = loss_fn(y_g_hat, val_labels)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            optimizer_meta.zero_grad()\n",
    "            l_g_meta.backward()\n",
    "            grad_eps = eps.grad\n",
    "        \n",
    "        w_tilde = torch.clamp(grad_eps,min=0)\n",
    "        norm_c = torch.sum(w_tilde)\n",
    "\n",
    "        if norm_c != 0:\n",
    "            w = w_tilde / norm_c\n",
    "        else:\n",
    "            w = w_tilde\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn_meta(outputs, labels)\n",
    "        loss = torch.sum(loss*w)\n",
    "        \n",
    "        # Backward pass and update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # Evaluate on test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    acc_list.append(accuracy) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meta-milo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3661111111111111, 0.44077777777777777, 0.49955555555555553, 0.5187777777777778, 0.5256666666666666, 0.5448888888888889, 0.5647777777777778, 0.5698888888888889, 0.5917777777777777, 0.6052222222222222, 0.6376666666666667, 0.6241111111111111, 0.6347777777777778, 0.6568888888888889, 0.6546666666666666, 0.661, 0.6761111111111111, 0.6602222222222223, 0.6622222222222223, 0.6893333333333334, 0.6777777777777778, 0.686, 0.686, 0.6961111111111111, 0.6658888888888889, 0.7047777777777777, 0.7133333333333334, 0.7023333333333334, 0.6986666666666667, 0.7231111111111111, 0.7243333333333334, 0.7223333333333334, 0.7211111111111111, 0.732, 0.7294444444444445, 0.7263333333333334, 0.733, 0.7331111111111112, 0.734, 0.7377777777777778]\n"
     ]
    }
   ],
   "source": [
    "print(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-milo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
