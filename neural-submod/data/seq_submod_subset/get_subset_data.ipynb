{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/ganesh/namitha/miniconda3/envs/submodlib-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from submodlib import FacilityLocationFunction, GraphCutFunction, DisparityMinFunction, DisparitySumFunction\n",
    "import pickle\n",
    "from itertools import permutations, combinations\n",
    "from torchvision import datasets\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = \"cifar10\"\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"../../data\", train=True, download=True)\n",
    "test_dataset = datasets.CIFAR10(root=\"../../data\", train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('..')\n",
    "# from utils.feature_extrater.cifar_feature_extractor import extract_features_threaded_worker, extract_features_resnet_threaded_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_permutations(data):\n",
    "#     \"\"\"Generates all permutations of a list.\"\"\"\n",
    "#     for permutation in permutations(data):\n",
    "#         yield permutation\n",
    "\n",
    "# def get_all_ordered_pairs(original_list):\n",
    "#     \"\"\"\n",
    "#     This function takes a list and returns all ordered pairs (lists of 2 elements)\n",
    "#     formed from the original list.\n",
    "#     \"\"\"\n",
    "#     for per in permutations(original_list, 2):\n",
    "#         yield per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_exp = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--exp'], dest='exp', nargs=None, const=None, default=2, type=<class 'int'>, choices=None, required=True, help='Why you want to generate subset?                            2: paraller_seq_data_geb                            4: seq_data_gen                            5: maa chudaye duniya wale', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"Program to generate sequential subset of data\",\n",
    "                                 formatter_class=argparse.RawTextHelpFormatter)\n",
    "\n",
    "parser.add_argument(\"--exp\", type=int,\n",
    "                    default=2,\n",
    "                    help=\"\"\"\n",
    "                        Why you want to generate subset?\n",
    "                        2: parallel_seq_data_gen\n",
    "                        4: seq_data_gen\n",
    "                        5: maa chudaye duniya wale\n",
    "                    \"\"\",\n",
    "                    required=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --exp EXP\n",
      "ipykernel_launcher.py: error: the following arguments are required: --exp\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/ganesh/namitha/miniconda3/envs/submodlib-env/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args()\n",
    "which_exp = args.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "which_exp = input(\"Why you want to generate subset?\\\n",
    "                   2: paraller_seq_data_geb\\\n",
    "                   4: seq_data_gen\\\n",
    "                   5: maa chudaye duniya wale\")\n",
    "which_exp = int(which_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [\"facility-location\", \"disparity-min\",  \"disparity-sum\", \"graph-cut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if which_exp==4:\n",
    "    subset_fraction_size = [0.5, 0.6, 0.5]\n",
    "elif which_exp==2:\n",
    "    subset_fraction_size = [0.3, 0.5]\n",
    "else:\n",
    "    print(\"Error: Experiment not defined!\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ls = os.listdir(f\"./permutation_subsets_{which_exp}\")\n",
    "for i, s in enumerate(dir_ls):\n",
    "    dir_ls[i]=dir_ls[i].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start (5000,) (5000,) 30 0\n"
     ]
    }
   ],
   "source": [
    "for order in permutations(func_list, which_exp):\n",
    "    per_func_list = list(order)\n",
    "    filename = \"\"\n",
    "\n",
    "    for func in per_func_list:\n",
    "        filename += func+\"_\"\n",
    "    filename = filename[:-1]\n",
    "\n",
    "    if filename in dir_ls:\n",
    "        continue;\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    with open(f\"../../../milo-base/cifar10/dataframe.pkl\", \"rb\") as f:\n",
    "        df = pickle.load(f)\n",
    "        \n",
    "    groups = df.groupby('Label')\n",
    "    dataframes = [group for _, group in groups]\n",
    "\n",
    "    for i, df in enumerate(dataframes):\n",
    "        df[\"Features\"] = df[\"Features\"].to_numpy()\n",
    "        df[\"Index\"] = df[\"Index\"].to_numpy()\n",
    "\n",
    "    list_indexes = []\n",
    "\n",
    "    if which_exp==2:\n",
    "        sz = 2\n",
    "    elif which_exp==4:\n",
    "        sz = 3\n",
    "\n",
    "    for idx in range(sz):\n",
    "        fraction_size = subset_fraction_size[idx]\n",
    "        final_indexes = []\n",
    "        for i, df in enumerate(dataframes):\n",
    "            features = df[\"Features\"].to_numpy()\n",
    "            indexes = df[\"Index\"].to_numpy()\n",
    "\n",
    "            print(\"start\", features.shape, indexes.shape)\n",
    "\n",
    "            if which_exp==4:\n",
    "                # can choose a different strategy \n",
    "                func = per_func_list[idx+i%2]\n",
    "            elif which_exp==2:\n",
    "                func = per_func_list[idx]\n",
    "\n",
    "            if func==\"facility-location\":\n",
    "                obj = FacilityLocationFunction(n=features.shape[0], data=features, separate_rep=False, mode=\"dense\", metric=\"cosine\")\n",
    "            elif func==\"disparity-min\":\n",
    "                obj = DisparityMinFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\")\n",
    "            elif func==\"disparity-sum\":\n",
    "                obj = DisparitySumFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\")\n",
    "            elif func==\"graph-cut\":\n",
    "                obj = GraphCutFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\", lambdaVal=0.45)\n",
    "            else:\n",
    "                raise Exception(\"Sorry, no submodlib function defined\")\n",
    "            \n",
    "            S = obj.maximize(int(fraction_size*features.shape[0]), optimizer='NaiveGreedy', stopIfZeroGain=False, stopIfNegativeGain=False, epsilon=0.1, verbose=False, show_progress=False, costs=None, costSensitiveGreedy=False)\n",
    "            # S = obj.maximize(30-10*idx, optimizer='NaiveGreedy', stopIfZeroGain=False, stopIfNegativeGain=False, epsilon=0.1, verbose=False, show_progress=True, costs=None, costSensitiveGreedy=False)\n",
    "            S = list(map(lambda tuple: tuple[0], S))\n",
    "\n",
    "            print(type(S))\n",
    "            indexes = indexes[S]\n",
    "            features = features[S]\n",
    "\n",
    "            final_indexes.extend(list(indexes))\n",
    "\n",
    "            _df = pd.DataFrame()\n",
    "            _df[\"Features\"] = features\n",
    "            _df[\"Index\"] = indexes\n",
    "\n",
    "            dataframes[i] = _df\n",
    "\n",
    "            print(\"end\", features.shape[0], indexes.shape[0])\n",
    "\n",
    "        list_indexes.append(final_indexes)\n",
    "        \n",
    "    with open(f\"permutation_subsets_{which_exp}/{filename}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(list_indexes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start (5000,) (5000,) 30 0\n",
      "<class 'list'>\n",
      "end 2500 2500\n",
      "start (2500,) (2500,) 20 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[||||||||||||||||||||]100% [Iteration 2500 of 2500]"
     ]
    }
   ],
   "source": [
    "# if which_exp==1:\n",
    "#     subset_fraction_size = [0.5, 0.6, 0.5]\n",
    "\n",
    "#     for order in generate_permutations(func_list):\n",
    "#         per_func_list = list(order)\n",
    "#         filename = \"\"\n",
    "#         for func in per_func_list:\n",
    "#             filename += func+\"_\"\n",
    "#         filename = filename[:-1]\n",
    "\n",
    "#         with open(f\"../../../milo-base/cifar10/dataframe.pkl\", \"rb\") as f:\n",
    "#             df = pickle.load(f)\n",
    "            \n",
    "#         groups = df.groupby('Label')\n",
    "#         dataframes = [group for _, group in groups]\n",
    "\n",
    "#         for i, df in enumerate(dataframes):\n",
    "#             df[\"Features\"] = df[\"Features\"].to_numpy()\n",
    "#             df[\"Index\"] = df[\"Index\"].to_numpy()\n",
    "\n",
    "\n",
    "#         list_indexes = []\n",
    "#         for idx in range(len(func_list)-1):\n",
    "#             fraction_size = subset_fraction_size[idx]\n",
    "#             final_indexes = []\n",
    "#             for i, df in enumerate(dataframes):\n",
    "#                 features = df[\"Features\"].to_numpy()\n",
    "#                 indexes = df[\"Index\"].to_numpy()\n",
    "\n",
    "#                 print(\"start\", features.shape, indexes.shape, 30-10*idx, idx)\n",
    "\n",
    "#                 # can choose a different strategy \n",
    "#                 func = per_func_list[idx+i%2]\n",
    "\n",
    "#                 if func==\"facility-location\":\n",
    "#                     obj = FacilityLocationFunction(n=features.shape[0], data=features, separate_rep=False, mode=\"dense\", metric=\"cosine\")\n",
    "#                 elif func==\"disparity-min\":\n",
    "#                     obj = DisparityMinFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\")\n",
    "#                 elif func==\"disparity-sum\":\n",
    "#                     obj = DisparitySumFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\")\n",
    "#                 elif func==\"graph-cut\":\n",
    "#                     obj = GraphCutFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\", lambdaVal=0.45)\n",
    "#                 else:\n",
    "#                     raise Exception(\"Sorry, no submodlib function defined\")\n",
    "                \n",
    "#                 S = obj.maximize(int(fraction_size*features.shape[0]), optimizer='NaiveGreedy', stopIfZeroGain=False, stopIfNegativeGain=False, epsilon=0.1, verbose=False, show_progress=True, costs=None, costSensitiveGreedy=False)\n",
    "#                 # S = obj.maximize(30-10*idx, optimizer='NaiveGreedy', stopIfZeroGain=False, stopIfNegativeGain=False, epsilon=0.1, verbose=False, show_progress=True, costs=None, costSensitiveGreedy=False)\n",
    "#                 S = list(map(lambda tuple: tuple[0], S))\n",
    "\n",
    "#                 print(type(S))\n",
    "#                 indexes = indexes[S]\n",
    "#                 features = features[S]\n",
    "\n",
    "#                 final_indexes.extend(list(indexes))\n",
    "\n",
    "#                 _df = pd.DataFrame()\n",
    "#                 _df[\"Features\"] = features\n",
    "#                 _df[\"Index\"] = indexes\n",
    "\n",
    "#                 dataframes[i] = _df\n",
    "\n",
    "#                 print(\"end\", features.shape[0], indexes.shape[0])\n",
    "\n",
    "#             list_indexes.append(final_indexes)\n",
    "#         print(list_indexes)\n",
    "            \n",
    "#         with open(f\"permutation_subsets/{filename}.pkl\", \"wb\") as f:\n",
    "#             pickle.dump(list_indexes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('facility-location', 'disparity-min', 'disparity-sum', 'graph-cut')\n",
      "('facility-location', 'disparity-min', 'graph-cut', 'disparity-sum')\n",
      "('facility-location', 'disparity-sum', 'disparity-min', 'graph-cut')\n",
      "('facility-location', 'disparity-sum', 'graph-cut', 'disparity-min')\n",
      "('facility-location', 'graph-cut', 'disparity-min', 'disparity-sum')\n",
      "('facility-location', 'graph-cut', 'disparity-sum', 'disparity-min')\n",
      "('disparity-min', 'facility-location', 'disparity-sum', 'graph-cut')\n",
      "('disparity-min', 'facility-location', 'graph-cut', 'disparity-sum')\n",
      "('disparity-min', 'disparity-sum', 'facility-location', 'graph-cut')\n",
      "('disparity-min', 'disparity-sum', 'graph-cut', 'facility-location')\n",
      "('disparity-min', 'graph-cut', 'facility-location', 'disparity-sum')\n",
      "('disparity-min', 'graph-cut', 'disparity-sum', 'facility-location')\n",
      "('disparity-sum', 'facility-location', 'disparity-min', 'graph-cut')\n",
      "('disparity-sum', 'facility-location', 'graph-cut', 'disparity-min')\n",
      "('disparity-sum', 'disparity-min', 'facility-location', 'graph-cut')\n",
      "('disparity-sum', 'disparity-min', 'graph-cut', 'facility-location')\n",
      "('disparity-sum', 'graph-cut', 'facility-location', 'disparity-min')\n",
      "('disparity-sum', 'graph-cut', 'disparity-min', 'facility-location')\n",
      "('graph-cut', 'facility-location', 'disparity-min', 'disparity-sum')\n",
      "('graph-cut', 'facility-location', 'disparity-sum', 'disparity-min')\n",
      "('graph-cut', 'disparity-min', 'facility-location', 'disparity-sum')\n",
      "('graph-cut', 'disparity-min', 'disparity-sum', 'facility-location')\n",
      "('graph-cut', 'disparity-sum', 'facility-location', 'disparity-min')\n",
      "('graph-cut', 'disparity-sum', 'disparity-min', 'facility-location')\n"
     ]
    }
   ],
   "source": [
    "# for i in permutations(func_list):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if which_exp==2:\n",
    "#     subset_fraction_size = [0.3, 0.5]\n",
    "\n",
    "#     for order in get_all_ordered_pairs(func_list):\n",
    "#         per_func_list = list(order)\n",
    "#         filename = \"\"\n",
    "#         for func in per_func_list:\n",
    "#             filename += func+\"_\"\n",
    "#         filename = filename[:-1]\n",
    "\n",
    "#         with open(f\"../../../milo-base/cifar10/dataframe.pkl\", \"rb\") as f:\n",
    "#             df = pickle.load(f)\n",
    "            \n",
    "#         groups = df.groupby('Label')\n",
    "#         dataframes = [group for _, group in groups]\n",
    "\n",
    "#         for i, df in enumerate(dataframes):\n",
    "#             df[\"Features\"] = df[\"Features\"].to_numpy()\n",
    "#             df[\"Index\"] = df[\"Index\"].to_numpy()\n",
    "\n",
    "\n",
    "#         list_indexes = []\n",
    "#         for idx in range(len(func_list)-1):\n",
    "#             fraction_size = subset_fraction_size[idx]\n",
    "#             final_indexes = []\n",
    "#             for i, df in enumerate(dataframes):\n",
    "#                 features = df[\"Features\"].to_numpy()\n",
    "#                 indexes = df[\"Index\"].to_numpy()\n",
    "\n",
    "#                 print(\"start\", features.shape, indexes.shape, 30-10*idx, idx)\n",
    "\n",
    "#                 # can choose a different strategy \n",
    "#                 func = func_list[idx+i%2]\n",
    "\n",
    "#                 if func==\"facility-location\":\n",
    "#                     obj = FacilityLocationFunction(n=features.shape[0], data=features, separate_rep=False, mode=\"dense\", metric=\"cosine\")\n",
    "#                 elif func==\"disparity-min\":\n",
    "#                     obj = DisparityMinFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\")\n",
    "#                 elif func==\"disparity-sum\":\n",
    "#                     obj = DisparitySumFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\")\n",
    "#                 elif func==\"graph-cut\":\n",
    "#                     obj = GraphCutFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\", lambdaVal=0.45)\n",
    "#                 else:\n",
    "#                     raise Exception(\"Sorry, no submodlib function defined\")\n",
    "                \n",
    "#                 S = obj.maximize(int(fraction_size*features.shape[0]), optimizer='NaiveGreedy', stopIfZeroGain=False, stopIfNegativeGain=False, epsilon=0.1, verbose=False, show_progress=True, costs=None, costSensitiveGreedy=False)\n",
    "#                 # S = obj.maximize(30-10*idx, optimizer='NaiveGreedy', stopIfZeroGain=False, stopIfNegativeGain=False, epsilon=0.1, verbose=False, show_progress=True, costs=None, costSensitiveGreedy=False)\n",
    "#                 S = list(map(lambda tuple: tuple[0], S))\n",
    "\n",
    "#                 print(type(S))\n",
    "#                 indexes = indexes[S]\n",
    "#                 features = features[S]\n",
    "\n",
    "#                 final_indexes.extend(list(indexes))\n",
    "\n",
    "#                 _df = pd.DataFrame()\n",
    "#                 _df[\"Features\"] = features\n",
    "#                 _df[\"Index\"] = indexes\n",
    "\n",
    "#                 dataframes[i] = _df\n",
    "\n",
    "#                 print(\"end\", features.shape[0], indexes.shape[0])\n",
    "\n",
    "#             list_indexes.append(final_indexes)\n",
    "#         print(list_indexes)\n",
    "            \n",
    "#         with open(f\"permutation_subsets/{filename}.pkl\", \"wb\") as f:\n",
    "#             pickle.dump(list_indexes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "submodlib-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
