{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/ganesh/namitha/miniconda3/envs/submodlib-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "from submodlib import FacilityLocationFunction, GraphCutFunction, DisparityMinFunction, DisparitySumFunction\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import timeit\n",
    "from itertools import permutations\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = \"cifar10\"\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"../../data\", train=True, download=True)\n",
    "test_dataset = datasets.CIFAR10(root=\"../../data\", train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('..')\n",
    "# from utils.feature_extrater.cifar_feature_extractor import extract_features_threaded_worker, extract_features_resnet_threaded_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutations(data):\n",
    "    \"\"\"Generates all permutations of a list.\"\"\"\n",
    "    for permutation in permutations(data):\n",
    "        yield permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../../../milo-base/cifar10/dataframe.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "    \n",
    "groups = df.groupby('Label')\n",
    "dataframes = [group for _, group in groups]\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "    df[\"Features\"] = df[\"Features\"].to_numpy()\n",
    "    df[\"Index\"] = df[\"Index\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [\"facility-location\", \"disparity-min\",  \"disparity-sum\", \"graph-cut\"]\n",
    "subset_fraction_size = [0.5, 0.6, 0.5]\n",
    "\n",
    "for order in generate_permutations(func_list):\n",
    "    per_func_list = list(order)\n",
    "    filename = \"\"\n",
    "    for func in per_func_list:\n",
    "        filename += func+\"_\"\n",
    "    filename = filename[:-1]\n",
    "\n",
    "    list_indexes = []\n",
    "    for idx in range(len(func_list)-1):\n",
    "        fraction_size = subset_fraction_size[idx]\n",
    "        final_indexes = []\n",
    "        for i, df in enumerate(dataframes):\n",
    "            features = df[\"Features\"]\n",
    "            indexes = df[\"Index\"]\n",
    "\n",
    "            # can choose a different strategy \n",
    "            func = func_list[idx+i%2]\n",
    "\n",
    "            if func==\"facility-location\":\n",
    "                obj = FacilityLocationFunction(n=features.shape[0], data=features, separate_rep=False, mode=\"dense\", metric=\"cosine\")\n",
    "            elif func==\"disparity-min\":\n",
    "                obj = DisparityMinFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\")\n",
    "            elif func==\"disparity-sum\":\n",
    "                obj = DisparitySumFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\")\n",
    "            elif func==\"graph-cut\":\n",
    "                obj = GraphCutFunction(n=features.shape[0], data=features, mode=\"dense\", metric=\"cosine\", lambdaVal=0.45)\n",
    "            else:\n",
    "                raise Exception(\"Sorry, no submodlib function defined\")\n",
    "            \n",
    "            S = obj.maximize(int(fraction_size*features.shape[0]), optimizer='NaiveGreedy', stopIfZeroGain=False, stopIfNegativeGain=False, epsilon=0.1, verbose=False, show_progress=True, costs=None, costSensitiveGreedy=False)\n",
    "            S = list(map(lambda tuple: tuple[0], S))\n",
    "\n",
    "            features = features[S]\n",
    "            indexes = indexes[S]\n",
    "\n",
    "            final_indexes.extend(list(indexes))\n",
    "\n",
    "            df[\"Features\"] = features\n",
    "            df[\"Index\"] = indexes\n",
    "\n",
    "        list_indexes.append(final_indexes)\n",
    "        \n",
    "    with open(f\"{filename}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(list_indexes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "submodlib-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
