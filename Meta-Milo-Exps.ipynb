{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77904680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f634e052570>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "import pickle\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68173d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:5\" # change the available gpu number\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ede7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_fraction = 0.3\n",
    "num_runs = 5\n",
    "split_ratio = 0.9\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "730a4e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25f166",
   "metadata": {},
   "source": [
    "### Load Resent Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867a90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resent18_model(num_classes=10):\n",
    "    model = torchvision.models.resnet18(weights=None)  # Use 'weights' for pretrained models\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def get_resent101_model(num_classes=10):\n",
    "    model = torchvision.models.resnet101(weights=None)  # Use 'weights' for pretrained models\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ee8f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.models.resnet.ResNet'>\n"
     ]
    }
   ],
   "source": [
    "model = get_resent101_model()\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebf2a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze pre-trained layers\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Unfreeze some layers for fine-tuning\n",
    "# for param in model.layer4.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9245b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f7d6e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 datasets\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f0ba7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7660594",
   "metadata": {},
   "source": [
    "## LeNet Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3640cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):    \n",
    "    def __init__(self, out_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(400,120),  #in_features = 16 x5x5 \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, out_classes),\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x): \n",
    "        a1=self.feature_extractor(x)\n",
    "        # print(a1.shape)\n",
    "        a1 = torch.flatten(a1,1)\n",
    "        a2=self.classifier(a1)\n",
    "        return a2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473020d",
   "metadata": {},
   "source": [
    "# Baseline Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9629936b",
   "metadata": {},
   "source": [
    "### Basic Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "time_per_run = []\n",
    "acc_per_run = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Define the Model\n",
    "    model = get_resent101_model(10)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train loop\n",
    "        for images, labels in train_dataloader:\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            # Backward pass and update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    time_taken = time.time() - start_time   \n",
    "    time_per_run.append(time_taken)  \n",
    "    print(\"--- %s seconds ---\" % (time_taken))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    acc_per_run.append(accuracy)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Epoch: [{epoch+1}/{epochs}], Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "acc_mean = statistics.mean(acc_per_run)\n",
    "acc_std = statistics.stdev(acc_per_run)\n",
    "\n",
    "time_mean = statistics.mean(time_per_run)\n",
    "time_std = statistics.stdev(time_per_run)\n",
    "\n",
    "print(f\"mean accuracy:{acc_mean}, std accuracy:{acc_std}\")\n",
    "print(f\"mean accuracy:{time_mean}, std accuracy:{time_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d32917e",
   "metadata": {},
   "source": [
    "# Reweight Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57482d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 datasets\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "\n",
    "n_samples = len(test_dataset)\n",
    "n_test = int(n_samples * split_ratio)\n",
    "n_val = n_samples - n_test\n",
    "test_dataset, val_dataset = random_split(test_dataset, [n_test, n_val])\n",
    "\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b2442",
   "metadata": {},
   "source": [
    "### Random Sampler for Sampling Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSubsetSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, dataset, subset_size):\n",
    "        self.dataset = dataset\n",
    "        self.subset_size = subset_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = random.sample(range(len(self.dataset)), self.subset_size)\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.subset_size\n",
    "\n",
    "subset_sampler = RandomSubsetSampler(val_dataset, 64)\n",
    "subset_dataloader = DataLoader(val_dataset, sampler=subset_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06798432",
   "metadata": {},
   "source": [
    "### Meta Baseline Trainloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541021a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "time_per_run = []\n",
    "acc_per_run = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Define the Model\n",
    "    model = LeNet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss_fn_meta = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train loop\n",
    "        for images, labels in train_dataloader:\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # meta_net = get_cifar10_model()\n",
    "            meta_net = LeNet()\n",
    "            meta_net.load_state_dict(model.state_dict())\n",
    "\n",
    "            meta_net = meta_net.to(device)\n",
    "\n",
    "            optimizer_meta = torch.optim.Adam(meta_net.parameters())\n",
    "\n",
    "            meta_net.train()\n",
    "            \n",
    "            y_f_hat = meta_net(images)\n",
    "            cost = loss_fn_meta(y_f_hat, labels)\n",
    "            eps = torch.zeros(cost.size(), requires_grad=True).to(device)\n",
    "            l_f_meta = torch.sum(cost*eps)\n",
    "\n",
    "            # meta_net.zero_grad()\n",
    "            optimizer_meta.zero_grad()\n",
    "            eps.retain_grad()\n",
    "            l_f_meta.backward()\n",
    "            optimizer_meta.step()\n",
    "\n",
    "            meta_net.eval()\n",
    "\n",
    "            # grads = torch.autograd.grad(l_f_meta, (meta_net.parameters()), create_graph=True)\n",
    "            # meta_net.update_params(lr, source_params=grads)\n",
    "            \n",
    "            val_images, val_labels = next(iter(subset_dataloader))\n",
    "            # val_images, val_labels = next(iter(val_dataloader))\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            y_g_hat = meta_net(val_images)\n",
    "            l_g_meta = loss_fn(y_g_hat, val_labels)\n",
    "\n",
    "            # grad_eps = torch.autograd.grad(l_g_meta, eps, only_inputs=True)[0]\n",
    "            # grad_eps = torch.autograd.grad(l_g_meta, eps, only_inputs=True, allow_unused=True)[0]\n",
    "            # print(grad_eps)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                optimizer_meta.zero_grad()\n",
    "                l_g_meta.backward()\n",
    "                grad_eps = eps.grad\n",
    "            \n",
    "            # print(grad_eps)\n",
    "            w_tilde = torch.clamp(grad_eps,min=0)\n",
    "            # w_tilde = torch.clamp(-grad_eps,min=0)\n",
    "            norm_c = torch.sum(w_tilde)\n",
    "\n",
    "            if norm_c != 0:\n",
    "                w = w_tilde / norm_c\n",
    "            else:\n",
    "                w = w_tilde\n",
    "            \n",
    "            # print(w)\n",
    "            # break\n",
    "            # Forward Pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn_meta(outputs, labels)\n",
    "            loss = torch.sum(loss*w)\n",
    "            \n",
    "            # Backward pass and update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    time_taken = time.time() - start_time   \n",
    "    time_per_run.append(time_taken)  \n",
    "    print(\"--- %s seconds ---\" % (time_taken))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    acc_per_run.append(accuracy)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd3ecc",
   "metadata": {},
   "source": [
    "# Milo Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc91f2e",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "class_data = []\n",
    "subset_fraction = 0.3\n",
    "for i in range(num_classes):\n",
    "    with open(f\"milo-base/class-data-{subset_fraction}/class_{i}.pkl\", \"rb\") as f:\n",
    "        S = pickle.load(f)\n",
    "        class_data.append(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sets = len(class_data[0])\n",
    "data = []\n",
    "for i in range(num_sets):\n",
    "    S = []\n",
    "    for j in range(num_classes):\n",
    "        S.extend(class_data[j][i])\n",
    "    data.append(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0452f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437bd49c",
   "metadata": {},
   "source": [
    "### Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22252b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubDataset(Dataset):\n",
    "    def __init__(self, indices, dataset):\n",
    "        self.indices = indices\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.indices[idx]\n",
    "        data_point = self.dataset[index]\n",
    "        return data_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3198ce4",
   "metadata": {},
   "source": [
    "## Milo Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3717bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_run = []\n",
    "acc_per_run = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Define Model\n",
    "    model = LeNet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    R = 1\n",
    "    start_time = time.time()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        # Train loop\n",
    "        if epoch%R==0:\n",
    "            sub_dataset = SubDataset(indices=data[epoch//R], dataset=train_dataset)\n",
    "            subset_train_dataloader = DataLoader(sub_dataset, batch_size=64, shuffle=True)\n",
    "            \n",
    "        for images, labels in subset_train_dataloader:\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            # Backward pass and update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    time_taken = time.time() - start_time   \n",
    "    time_per_run.append(time_taken)  \n",
    "    print(\"--- %s seconds ---\" % (time_taken))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    acc_per_run.append(accuracy)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 datasets\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "\n",
    "n_samples = len(test_dataset)\n",
    "n_test = int(n_samples * split_ratio)\n",
    "n_val = n_samples - n_test\n",
    "test_dataset, val_dataset = random_split(test_dataset, [n_test, n_val])\n",
    "\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95851238",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_sampler = RandomSubsetSampler(val_dataset, 64)\n",
    "subset_dataloader = DataLoader(val_dataset, sampler=subset_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146446a",
   "metadata": {},
   "source": [
    "### Meta-Milo Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_run = []\n",
    "acc_per_run = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Define Model\n",
    "    model = LeNet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss_fn_meta = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train loop\n",
    "\n",
    "        if epoch%R==0:\n",
    "            sub_dataset = SubDataset(indices=data[epoch//R], dataset=train_dataset)\n",
    "            # train_dataloader = DataLoader(sub_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "            train_dataloader = DataLoader(sub_dataset, batch_size=64, shuffle=True)\n",
    "        \n",
    "        for images, labels in train_dataloader:\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # meta_net = get_cifar10_model()\n",
    "            meta_net = LeNet()\n",
    "            meta_net.load_state_dict(model.state_dict())\n",
    "\n",
    "            meta_net = meta_net.to(device)\n",
    "\n",
    "            optimizer_meta = torch.optim.Adam(meta_net.parameters())\n",
    "\n",
    "            meta_net.train()\n",
    "            \n",
    "            y_f_hat = meta_net(images)\n",
    "            cost = loss_fn_meta(y_f_hat, labels)\n",
    "            eps = torch.zeros(cost.size(), requires_grad=True).to(device)\n",
    "            l_f_meta = torch.sum(cost*eps)\n",
    "\n",
    "            # meta_net.zero_grad()\n",
    "            optimizer_meta.zero_grad()\n",
    "            eps.retain_grad()\n",
    "            l_f_meta.backward()\n",
    "            optimizer_meta.step()\n",
    "\n",
    "            meta_net.eval()\n",
    "\n",
    "            # grads = torch.autograd.grad(l_f_meta, (meta_net.parameters()), create_graph=True)\n",
    "            # meta_net.update_params(lr, source_params=grads)\n",
    "            \n",
    "            val_images, val_labels = next(iter(subset_dataloader))\n",
    "            # val_images, val_labels = next(iter(val_dataloader))\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            y_g_hat = meta_net(val_images)\n",
    "            l_g_meta = loss_fn(y_g_hat, val_labels)\n",
    "\n",
    "            # grad_eps = torch.autograd.grad(l_g_meta, eps, only_inputs=True)[0]\n",
    "            # grad_eps = torch.autograd.grad(l_g_meta, eps, only_inputs=True, allow_unused=True)[0]\n",
    "            # print(grad_eps)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                optimizer_meta.zero_grad()\n",
    "                l_g_meta.backward()\n",
    "                grad_eps = eps.grad\n",
    "            \n",
    "            # print(grad_eps)\n",
    "            w_tilde = torch.clamp(grad_eps,min=0)\n",
    "            # w_tilde = torch.clamp(-grad_eps,min=0)\n",
    "            norm_c = torch.sum(w_tilde)\n",
    "\n",
    "            if norm_c != 0:\n",
    "                w = w_tilde / norm_c\n",
    "            else:\n",
    "                w = w_tilde\n",
    "            \n",
    "            # print(w)\n",
    "            # break\n",
    "            # Forward Pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn_meta(outputs, labels)\n",
    "            loss = torch.sum(loss*w)\n",
    "            \n",
    "            # Backward pass and update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    time_taken = time.time() - start_time   \n",
    "    time_per_run.append(time_taken)  \n",
    "    print(\"--- %s seconds ---\" % (time_taken))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    acc_per_run.append(accuracy)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb8cb9",
   "metadata": {},
   "source": [
    "## Random Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6468723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 datasets\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "subset_size = int(subset_fraction * len(train_dataset))  # 30% of the full dataset\n",
    "subset_indices = torch.randperm(len(train_dataset))[:subset_size]  # Randomly select indices\n",
    "subset_dataset = torch.utils.data.Subset(train_dataset, subset_indices)  # Create the subset\n",
    "\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(subset_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ea383d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:5\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32249fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 93.38it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 97.50it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 100.48it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 95.77it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 87.00it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 80.80it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 98.00it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 104.23it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 99.71it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 84.56it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 78.39it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 98.65it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 101.49it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 91.27it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 82.49it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 97.66it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 98.85it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 98.26it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 90.93it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 88.08it/s]\n",
      "100%|██████████| 20/20 [00:50<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 50.73576307296753 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 133.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 94.88it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 90.04it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 80.06it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 79.08it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 93.72it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 96.93it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 86.91it/s]\n",
      "100%|██████████| 235/235 [00:03<00:00, 74.59it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 90.88it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 98.90it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 97.53it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 88.46it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 85.06it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 87.82it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 93.45it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 99.33it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 87.18it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 84.33it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 92.64it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 99.87it/s] \n",
      "100%|██████████| 20/20 [00:52<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 52.57818102836609 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 139.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 89.82it/s]\n",
      "100%|██████████| 235/235 [00:03<00:00, 76.64it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 87.76it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 99.43it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 95.99it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 86.20it/s]\n",
      "100%|██████████| 235/235 [00:03<00:00, 74.72it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 84.03it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 90.97it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 96.20it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 88.57it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 84.12it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 95.42it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 99.21it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 94.94it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 85.14it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 85.64it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 100.19it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 101.65it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 86.60it/s]\n",
      "100%|██████████| 20/20 [00:52<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 52.58237981796265 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 115.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 82.89it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 89.00it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 94.40it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 89.01it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 90.74it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 93.86it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 102.42it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 97.48it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 91.14it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 83.73it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 90.05it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 98.73it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 93.01it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 89.21it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 87.83it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 97.80it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 103.49it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 85.42it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 82.45it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 90.91it/s] \n",
      "100%|██████████| 20/20 [00:51<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 51.550086975097656 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 122.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:02<00:00, 100.53it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 88.19it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 84.81it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 92.11it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 100.07it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 100.96it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 86.25it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 81.32it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 93.83it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 97.21it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 92.76it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 85.40it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 85.53it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 96.30it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 86.30it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 82.47it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 79.42it/s]\n",
      "100%|██████████| 235/235 [00:02<00:00, 89.21it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 98.06it/s] \n",
      "100%|██████████| 235/235 [00:02<00:00, 86.63it/s]\n",
      "100%|██████████| 20/20 [00:52<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 52.40761351585388 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:01<00:00, 114.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "time_per_run = []\n",
    "acc_per_run = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Define the Model\n",
    "    model = LeNet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train loop\n",
    "        for images, labels in train_dataloader:\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            # Backward pass and update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    time_taken = time.time() - start_time   \n",
    "    time_per_run.append(time_taken)  \n",
    "    print(\"--- %s seconds ---\" % (time_taken))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    acc_per_run.append(accuracy)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Epoch: [{epoch+1}/{epochs}], Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e039f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50.73576307296753, 52.57818102836609, 52.58237981796265, 51.550086975097656, 52.40761351585388]\n",
      "[0.5683, 0.5755, 0.5592, 0.5867, 0.5793]\n"
     ]
    }
   ],
   "source": [
    "print(time_per_run)\n",
    "print(acc_per_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b75ad8a",
   "metadata": {},
   "source": [
    "## Random Subset Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a22bcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load CIFAR10 datasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform_train)\n\u001b[1;32m      3\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform_test)\n\u001b[1;32m      6\u001b[0m subset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(subset_fraction \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataset))  \u001b[38;5;66;03m# 30% of the full dataset\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Load CIFAR10 datasets\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "subset_size = int(subset_fraction * len(train_dataset))  # 30% of the full dataset\n",
    "subset_indices = torch.randperm(len(train_dataset))[:subset_size]  # Randomly select indices\n",
    "subset_dataset = torch.utils.data.Subset(train_dataset, subset_indices)  # Create the subset\n",
    "\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(subset_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527fb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "for i in range(num_runs):\n",
    "    # Define the Model\n",
    "    model = LeNet()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss_fn_meta = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train loop\n",
    "        for images, labels in train_dataloader:\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # meta_net = get_cifar10_model()\n",
    "            meta_net = LeNet()\n",
    "            meta_net.load_state_dict(model.state_dict())\n",
    "\n",
    "            meta_net = meta_net.to(device)\n",
    "\n",
    "            optimizer_meta = torch.optim.Adam(meta_net.parameters())\n",
    "\n",
    "            meta_net.train()\n",
    "            \n",
    "            y_f_hat = meta_net(images)\n",
    "            cost = loss_fn_meta(y_f_hat, labels)\n",
    "            eps = torch.zeros(cost.size(), requires_grad=True).to(device)\n",
    "            l_f_meta = torch.sum(cost*eps)\n",
    "\n",
    "            # meta_net.zero_grad()\n",
    "            optimizer_meta.zero_grad()\n",
    "            eps.retain_grad()\n",
    "            l_f_meta.backward()\n",
    "            optimizer_meta.step()\n",
    "\n",
    "            meta_net.eval()\n",
    "\n",
    "            # grads = torch.autograd.grad(l_f_meta, (meta_net.parameters()), create_graph=True)\n",
    "            # meta_net.update_params(lr, source_params=grads)\n",
    "            \n",
    "            val_images, val_labels = next(iter(subset_dataloader))\n",
    "            # val_images, val_labels = next(iter(val_dataloader))\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            y_g_hat = meta_net(val_images)\n",
    "            l_g_meta = loss_fn(y_g_hat, val_labels)\n",
    "\n",
    "            # grad_eps = torch.autograd.grad(l_g_meta, eps, only_inputs=True)[0]\n",
    "            # grad_eps = torch.autograd.grad(l_g_meta, eps, only_inputs=True, allow_unused=True)[0]\n",
    "            # print(grad_eps)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                optimizer_meta.zero_grad()\n",
    "                l_g_meta.backward()\n",
    "                grad_eps = eps.grad\n",
    "            \n",
    "            # print(grad_eps)\n",
    "            w_tilde = torch.clamp(grad_eps,min=0)\n",
    "            # w_tilde = torch.clamp(-grad_eps,min=0)\n",
    "            norm_c = torch.sum(w_tilde)\n",
    "\n",
    "            if norm_c != 0:\n",
    "                w = w_tilde / norm_c\n",
    "            else:\n",
    "                w = w_tilde\n",
    "            \n",
    "            # print(w)\n",
    "            # break\n",
    "            # Forward Pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn_meta(outputs, labels)\n",
    "            loss = torch.sum(loss*w)\n",
    "            \n",
    "            # Backward pass and update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    \n",
    "    time_taken = time.time() - start_time   \n",
    "    time_per_run.append(time_taken)  \n",
    "    print(\"--- %s seconds ---\" % (time_taken))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    acc_per_run.append(accuracy)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-milo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
