{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7799f2-ff2f-4e5b-9b1c-6e55baea484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np\n",
    "from submodlib import FacilityLocationFunction, GraphCutFunction\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt(\"np.csv\", delimiter=\",\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86acad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_greedy(D, k, objFL, ϵ=1e-2, n=10, test=False):\n",
    "    \"\"\"Samples n subsets using stochastic-greedy.\n",
    "    Args:\n",
    "        D: number of training example\n",
    "        k: The subset size.\n",
    "        objFL: submodular function for conditional gain calculation\n",
    "        ϵ: The error tolerance.\n",
    "        n: The number of subsets to sample.\n",
    "\n",
    "    Returns:\n",
    "        A list of n subsets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize empty subsets\n",
    "    S = [set() for _ in range(n)]\n",
    "    # Set random subset size for the stochastic-greedy algorithm\n",
    "    s = int(D * math.log(1 / ϵ) / k)\n",
    "    for i in tqdm(range(n)):\n",
    "        for j in range(k):\n",
    "            # Sample a random subset by sampling s elements from D \\ Si\n",
    "            R = random.choices(list(set(range(D)) - S[i]), k=s)\n",
    "            # Use map to calculate marginal gains for all values in R with the custom set\n",
    "            marginal_gains = list(map(lambda r: objFL.marginalGain(S[i], r), R))\n",
    "            max_index = np.argmax(marginal_gains)\n",
    "            max_r = R[max_index]\n",
    "            S[i].add(max_r)\n",
    "            if test:\n",
    "                print(R)\n",
    "                print(marginal_gains)\n",
    "                print(max_index, max_r)\n",
    "                return S\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0192b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGE_optimised(D, k, objFL, ϵ=1e-2, n=10, test=False):\n",
    "    \"\"\"Samples n subsets using stochastic-greedy.\n",
    "    Args:\n",
    "        D: number of training example\n",
    "        k: The subset size.\n",
    "        objFL: submodular function for conditional gain calculation\n",
    "        ϵ: The error tolerance.\n",
    "        n: The number of subsets to sample.\n",
    "\n",
    "    Returns:\n",
    "        A list of n subsets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize empty subsets\n",
    "    S = [set() for _ in range(n)]\n",
    "    # Set random subset size for the stochastic-greedy algorithm\n",
    "    s = int(D * math.log(1 / ϵ) / k)\n",
    "    for i in tqdm(range(n)):\n",
    "        for j in range(k):\n",
    "            # Sample a random subset by sampling s elements from D \\ Si\n",
    "            R = random.choices(list(set(range(D)) - S[i]), k=s)\n",
    "            # Use map to calculate marginal gains for all values in R with the custom set\n",
    "            marginal_gains = list(map(lambda r: objFL.marginalGainWithMemoization(S[i], r), R))\n",
    "            max_index = np.argmax(marginal_gains)\n",
    "            max_r = R[max_index]\n",
    "            objFL.updateMemoization(S[i], max_r)\n",
    "            S[i].add(max_r)\n",
    "            if test:\n",
    "                print(R)\n",
    "                print(marginal_gains)\n",
    "                print(max_index, max_r)\n",
    "                return S\n",
    "        objFL.clearMemoization()\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d58329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WRE(D, k, obj, n=10):\n",
    "    \"\"\"Samples n subsets using weighted random exploration.\n",
    "    Args:\n",
    "        D: number of training example\n",
    "        k: The subset size.\n",
    "        objFL: submodular function for conditional gain calculation\n",
    "        n: The number of subsets to sample.\n",
    "    Returns:\n",
    "        A list of n subsets.\n",
    "    \"\"\"\n",
    "\n",
    "    A = set()\n",
    "    G = np.zeros(D)\n",
    "    for i in range(D):\n",
    "        R = list(set(range(D))-A)\n",
    "        marginal_gains = list(map(lambda r: obj.marginalGain(A, r), R))\n",
    "        max_index = np.argmax(marginal_gains)\n",
    "        max_r = R[max_index]\n",
    "        G[max_r] = marginal_gains[max_index]\n",
    "        A.add(max_r)\n",
    "    ts = 1+G+0.5*G**2\n",
    "    ts = ts/np.sum(ts)\n",
    "    S = [set() for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        S[i] = np.random.choice(len(ts), size=k, p=ts, replace=False)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WRE_optimised(D, k, obj, n=10):\n",
    "    \"\"\"Samples n subsets using weighted random exploration.\n",
    "    Args:\n",
    "        D: number of training example\n",
    "        k: The subset size.\n",
    "        obj: submodular function for conditional gain calculation\n",
    "        n: The number of subsets to sample.\n",
    "    Returns:\n",
    "        A list of n subsets.\n",
    "    \"\"\"\n",
    "\n",
    "    A = set()\n",
    "    G = np.zeros(D)\n",
    "    for i in tqdm(range(D)):\n",
    "        R = list(set(range(D))-A)\n",
    "        # if i%100==99:\n",
    "            # print(len(R))\n",
    "        marginal_gains = list(map(lambda r: obj.marginalGainWithMemoization(A, r), R))\n",
    "        max_index = np.argmax(marginal_gains)\n",
    "        max_r = R[max_index]\n",
    "        G[max_r] = marginal_gains[max_index]\n",
    "        obj.updateMemoization(A, max_r)\n",
    "        A.add(max_r)\n",
    "    ts = 1+G+0.5*G**2\n",
    "    ts = ts/np.sum(ts)\n",
    "    S = [set() for _ in range(n)]\n",
    "    for i in tqdm(range(n)):\n",
    "        S[i] = np.random.choice(len(ts), size=k, p=ts, replace=False)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d73ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WRE_max(D, k, obj, n=10):\n",
    "    \"\"\"Samples n subsets using weighted random exploration.\n",
    "    Args:\n",
    "        D: number of training example\n",
    "        k: The subset size.\n",
    "        obj: submodular function for conditional gain calculation\n",
    "        n: The number of subsets to sample.\n",
    "    Returns:\n",
    "        A list of n subsets.\n",
    "    \"\"\"\n",
    "\n",
    "    A = set()\n",
    "    G = np.zeros(D)\n",
    "    for i in tqdm(range(D)):\n",
    "        R = list(set(range(D))-A)\n",
    "        marginal_gains = list(map(lambda r: obj.marginalGainWithMemoization(A, r), R))\n",
    "        max_index = np.argmax(marginal_gains)\n",
    "        max_r = R[max_index]\n",
    "        G[max_r] = marginal_gains[max_index]\n",
    "        obj.updateMemoization(A, max_r)\n",
    "        A.add(max_r)\n",
    "    ts = 1+G+0.5*G**2\n",
    "    ts = ts/np.sum(ts)\n",
    "    S = [set() for _ in range(n)]\n",
    "    for i in tqdm(range(n)):\n",
    "        S[i] = np.random.choice(len(ts), size=k, p=ts, replace=False)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e0eac-cfa6-430f-b285-afb63112163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def euclidean_distance(data, i, j):\n",
    "    return np.linalg.norm(data[i] - data[j])\n",
    "\n",
    "def euclidean_kernel_threaded(data, n_threads=8):\n",
    "    n_samples = data.shape[0]\n",
    "    kernel = np.zeros((n_samples, n_samples))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=n_threads) as executor:\n",
    "        tasks = []\n",
    "        for i in range(n_samples):\n",
    "            for j in range(i + 1, n_samples):\n",
    "                tasks.append(executor.submit(euclidean_distance, data, i, j))\n",
    "\n",
    "        for i, j, future in zip(*[iter(tasks)] * 3):\n",
    "            distance = future.result()\n",
    "            kernel[i, j] = 1 / (distance**2 + 1e-8)\n",
    "            kernel[j, i] = kernel[i, j]\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda4f3b-52db-4e2b-8f99-caffe78e2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = euclidean_kernel_threaded(data)\n",
    "# print(kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataframe.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef188525",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby('Label')\n",
    "dataframes = [group for _, group in groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "list_of_class_wise_subsets = []\n",
    "for i, df in enumerate(dataframes):\n",
    "    features = df[\"Features\"].to_numpy()\n",
    "    objFL = FacilityLocationFunction(n=features.shape[0], data=features, separate_rep=False, mode=\"dense\", metric=\"cosine\")\n",
    "    S = SGE_optimised(features.shape[0], features.shape[0]//10, objFL, n=20)\n",
    "    with open(f\"./class-data/class_{i}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(S, f)\n",
    "    list_of_class_wise_subsets.append(S)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70046b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./class-data/class_0.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75156bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataframes[0][\"Features\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a48481",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccff871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from submodlib import FacilityLocationFunction\n",
    "objFL = FacilityLocationFunction(n=features.shape[0], data=features, separate_rep=False, mode=\"sparse\", metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e99de",
   "metadata": {},
   "outputs": [],
   "source": [
    "objGC = GraphCutFunction(n=features.shape[0], data=features, separate_rep=False, mode=\"dense\", metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d08d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "S = objFL.maximize(features.shape[0]-1, optimizer='NaiveGreedy', stopIfZeroGain=False, stopIfNegativeGain=False, epsilon=0.1, verbose=False, show_progress=True, costs=None, costSensitiveGreedy=False)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = objFL.maximize(features.shape[0]-1, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c1a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Why is this running slow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e73c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = WRE_optimised(features.shape[0], features.shape[0]//10, objFL, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff0483",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = stochastic_greedy(features.shape[0], features.shape[0]//10, objFL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9c548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = stochastic_greedy(features.shape[0], features.shape[0]//10, objFL, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = dataframes[1][\"Features\"].to_numpy()\n",
    "objFL2 = FacilityLocationFunction(n=features2.shape[0], data=features2, separate_rep=False, mode=\"dense\", metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd0bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = SGE_optimised(features2.shape[0], features2.shape[0]//10, objFL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3 = WRE_optimised(features2.shape[0], features2.shape[0]//10, objFL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def calculate_iou(set1, set2):\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    iou = len(intersection) / len(union)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def calculate_iou_matrix(sets_of_integers):\n",
    "    num_sets = len(sets_of_integers)\n",
    "    iou_matrix = np.zeros((num_sets, num_sets))\n",
    "\n",
    "    for i, j in itertools.combinations(range(num_sets), 2):\n",
    "        set1 = sets_of_integers[i]\n",
    "        set2 = sets_of_integers[j]\n",
    "        iou = calculate_iou(set1, set2)\n",
    "        iou_matrix[i, j] = iou\n",
    "        iou_matrix[j, i] = iou  # Fill the symmetric part\n",
    "\n",
    "    return iou_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad87f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_iou(S2[0], S2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aadfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_matrix = calculate_iou_matrix(S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c326146",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iou_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec945516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "submodlib-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
