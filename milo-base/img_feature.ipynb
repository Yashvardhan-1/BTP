{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import random\n",
    "# from submodlib import FacilityLocationFunction\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U datasets -y\n",
    "%pip uninstall fsspec \n",
    "%pip install fsspec==2023.9.2 -y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cifar10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img, resnet):\n",
    "    \"\"\"\n",
    "        :param img: A CIFAR image\n",
    "        :return: List of features\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply the transformation and convert the image to a tensor\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "    # Extract the features using the ResNet18 model\n",
    "    with torch.no_grad():\n",
    "        features = resnet(img_tensor)\n",
    "\n",
    "    # Flatten the features and convert to a 1D numpy array\n",
    "    features = features.squeeze().numpy()\n",
    "    features = features.flatten()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_threaded_worker(img_queue, index_list, features_list, label_list, features_lock, model, event):\n",
    "    processed_images = 0\n",
    "    while True:\n",
    "        # Get an image path from the queue\n",
    "        if img_queue.empty():\n",
    "            # Wait for the main thread to signal that all of the images have been enqueued\n",
    "            event.wait()\n",
    "\n",
    "            # If the queue is still empty, break out of the loop\n",
    "            if img_queue.empty():\n",
    "                break\n",
    "\n",
    "        index, img_path, label = img_queue.get()\n",
    "\n",
    "        # Extract the features from the image\n",
    "        img_features = extract_features(img_path, model)\n",
    "\n",
    "        # Acquire the lock\n",
    "        features_lock.acquire()\n",
    "\n",
    "        # Add the extracted features to the list\n",
    "        features_list.append(img_features)\n",
    "        index_list.append(index)\n",
    "        label_list.append(label)\n",
    "\n",
    "        # Release the lock\n",
    "        features_lock.release()\n",
    "        \n",
    "        # Increment the number of processed images\n",
    "        processed_images+=1\n",
    "\n",
    "        # If the thread has processed 1000 images, print the thread ID and the number of processed images\n",
    "        if processed_images % 1000 == 0:\n",
    "            print(f\"Thread ID: {threading.current_thread().ident} | Processed images: {processed_images}\")\n",
    "\n",
    "        # If the queue is empty, break out of the loop\n",
    "        if img_queue.empty():\n",
    "            print(f\"Thread ID: {threading.current_thread().ident} | Processed images: {processed_images}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_features_resnet_threaded_cifar(cifar_dataset, num_threads=4 ):\n",
    "    # Create a threading.Event object\n",
    "    event = threading.Event()\n",
    "    \n",
    "    num_imgs = len(cifar_dataset)\n",
    "\n",
    "    # Create a queue to store the image data\n",
    "    img_queue = queue.Queue()\n",
    "\n",
    "    # Create a list to store the extracted features\n",
    "    features_list = []\n",
    "    label_list = []\n",
    "    index_list = []\n",
    "\n",
    "    # Create a lock to protect the features list\n",
    "    features_lock = threading.Lock()\n",
    "\n",
    "    # Create a list of threads\n",
    "    threads = []\n",
    "    models = []\n",
    "\n",
    "    # create multiple copies of the models for extracting features\n",
    "    for i in range(num_threads):\n",
    "        models.append(torch.hub.load('pytorch/vision:v0.11.3', 'resnet18', pretrained=True))\n",
    "\n",
    "    # Start the threads\n",
    "    for i in range(num_threads):\n",
    "        thread = threading.Thread(target=extract_features_threaded_worker, args=(img_queue, index_list, features_list, label_list, features_lock, models[i], event))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    # Enqueue all the image data\n",
    "    for i, img in tqdm(enumerate(cifar_dataset)):\n",
    "        img_queue.put((i, img[\"img\"], img[\"label\"]))\n",
    "\n",
    "    # Signal to the threads that all of the images have been enqueued\n",
    "    event.set()\n",
    "\n",
    "    # Wait for all of the threads to finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    # Create a DataFrame from the extracted features\n",
    "    data = {'Index': index_list, 'Label': label_list, 'Features': features_list}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_dataset(dataset, model):\n",
    "    num_imgs = len(dataset)\n",
    "\n",
    "    # Create a list to store the extracted features\n",
    "    features_list = []\n",
    "    label_list = []\n",
    "    index_list = []\n",
    "\n",
    "    # Enqueue all the image data\n",
    "    for i, img in tqdm(enumerate(dataset)):\n",
    "        features = extract_features(img[\"img\"], model)\n",
    "        features_list.append(features)\n",
    "        label_list.append(img[\"label\"])\n",
    "        index_list.append(i)\n",
    "        if i%1000==999:\n",
    "            print(time.strftime('%X'))\n",
    "\n",
    "    # Create a DataFrame from the extracted features\n",
    "    data = {'Index': index_list, 'Label': label_list, 'Features': features_list}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset):\n",
    "    # Load the ResNet18 model\n",
    "    resnet = torch.hub.load('pytorch/vision:v0.11.3', 'resnet18', pretrained=True)\n",
    "    train_dataset = dataset[\"train\"]\n",
    "    df = get_features_dataset(train_dataset, resnet)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ResNet18 model\n",
    "resnet = torch.hub.load('pytorch/vision:v0.11.3', 'resnet18', pretrained=True)\n",
    "df = extract_features_resnet_threaded_cifar(dataset[\"train\"])\n",
    "\n",
    "# sort the dataframe by index\n",
    "df = df.sort_values(by='Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df[\"Features\"][0]))\n",
    "import pickle\n",
    "with open(f\"{dataset}/dataframe.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{dataset}/dataframe.pkl\", \"rb\") as f:\n",
    "    loaded_df = pickle.load(f)\n",
    "\n",
    "print(type(loaded_df[\"Features\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features DataFrame to a CSV file\n",
    "filename = \"features_cifar_check.csv\"\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "np_array = np.array(df['Features'])\n",
    "flattened_array = np_array.tolist()\n",
    "# Create a DataFrame from the flattened array\n",
    "df = pd.DataFrame(flattened_array)\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('np.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"subset_gen_time.pkl\", \"rb\") as f:\n",
    "    subset_gen_time = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'facility-location': {'[0.05, 0.1, 0.15, 0.3, 0.5]': 385.6713745482266}}\n"
     ]
    }
   ],
   "source": [
    "print(subset_gen_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-milo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
