{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "# from datasets import load_dataset\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U datasets -y\n",
    "# %pip uninstall fsspec \n",
    "# %pip install fsspec==2023.9.2 -y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cifar10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "# dataset = load_dataset(dataset_name)\n",
    "# cifar10 = load_dataset(\"cifar10\")\n",
    "\n",
    "from datasets import config\n",
    "config.cache_dir = None  # Disable caching temporarily\n",
    "cifar10 = load_dataset(\"cifar10\")\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img, resnet):\n",
    "    \"\"\"\n",
    "        :param img: A CIFAR image\n",
    "        :return: List of features\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply the transformation and convert the image to a tensor\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "    # Extract the features using the ResNet18 model\n",
    "    with torch.no_grad():\n",
    "        features = resnet(img_tensor)\n",
    "\n",
    "    # Flatten the features and convert to a 1D numpy array\n",
    "    features = features.squeeze().numpy()\n",
    "    features = features.flatten()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_threaded_worker(img_queue, index_list, features_list, label_list, features_lock, model, event):\n",
    "    processed_images = 0\n",
    "    while True:\n",
    "        # Get an image path from the queue\n",
    "        if img_queue.empty():\n",
    "            # Wait for the main thread to signal that all of the images have been enqueued\n",
    "            event.wait()\n",
    "\n",
    "            # If the queue is still empty, break out of the loop\n",
    "            if img_queue.empty():\n",
    "                break\n",
    "\n",
    "        index, img_path, label = img_queue.get()\n",
    "\n",
    "        # Extract the features from the image\n",
    "        img_features = extract_features(img_path, model)\n",
    "\n",
    "        # Acquire the lock\n",
    "        features_lock.acquire()\n",
    "\n",
    "        # Add the extracted features to the list\n",
    "        features_list.append(img_features)\n",
    "        index_list.append(index)\n",
    "        label_list.append(label)\n",
    "\n",
    "        # Release the lock\n",
    "        features_lock.release()\n",
    "        \n",
    "        # Increment the number of processed images\n",
    "        processed_images+=1\n",
    "\n",
    "        # If the thread has processed 1000 images, print the thread ID and the number of processed images\n",
    "        if processed_images % 1000 == 0:\n",
    "            print(f\"Thread ID: {threading.current_thread().ident} | Processed images: {processed_images}\")\n",
    "\n",
    "        # If the queue is empty, break out of the loop\n",
    "        if img_queue.empty():\n",
    "            print(f\"Thread ID: {threading.current_thread().ident} | Processed images: {processed_images}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_features_resnet_threaded_cifar(cifar_dataset, num_threads=4 ):\n",
    "    # Create a threading.Event object\n",
    "    event = threading.Event()\n",
    "    \n",
    "    num_imgs = len(cifar_dataset)\n",
    "\n",
    "    # Create a queue to store the image data\n",
    "    img_queue = queue.Queue()\n",
    "\n",
    "    # Create a list to store the extracted features\n",
    "    features_list = []\n",
    "    label_list = []\n",
    "    index_list = []\n",
    "\n",
    "    # Create a lock to protect the features list\n",
    "    features_lock = threading.Lock()\n",
    "\n",
    "    # Create a list of threads\n",
    "    threads = []\n",
    "    models = []\n",
    "\n",
    "    # create multiple copies of the models for extracting features\n",
    "    for i in range(num_threads):\n",
    "        models.append(torch.hub.load('pytorch/vision:v0.11.3', 'resnet18', pretrained=True))\n",
    "\n",
    "    # Start the threads\n",
    "    for i in range(num_threads):\n",
    "        thread = threading.Thread(target=extract_features_threaded_worker, args=(img_queue, index_list, features_list, label_list, features_lock, models[i], event))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    # Enqueue all the image data\n",
    "    for i, img in tqdm(enumerate(cifar_dataset)):\n",
    "        img_queue.put((i, img[\"img\"], img[\"label\"]))\n",
    "\n",
    "    # Signal to the threads that all of the images have been enqueued\n",
    "    event.set()\n",
    "\n",
    "    # Wait for all of the threads to finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    # Create a DataFrame from the extracted features\n",
    "    data = {'Index': index_list, 'Label': label_list, 'Features': features_list}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_dataset(dataset, model):\n",
    "    num_imgs = len(dataset)\n",
    "\n",
    "    # Create a list to store the extracted features\n",
    "    features_list = []\n",
    "    label_list = []\n",
    "    index_list = []\n",
    "\n",
    "    # Enqueue all the image data\n",
    "    for i, img in tqdm(enumerate(dataset)):\n",
    "        features = extract_features(img[\"img\"], model)\n",
    "        features_list.append(features)\n",
    "        label_list.append(img[\"label\"])\n",
    "        index_list.append(i)\n",
    "        if i%1000==999:\n",
    "            print(time.strftime('%X'))\n",
    "\n",
    "    # Create a DataFrame from the extracted features\n",
    "    data = {'Index': index_list, 'Label': label_list, 'Features': features_list}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset):\n",
    "    # Load the ResNet18 model\n",
    "    resnet = torch.hub.load('pytorch/vision:v0.11.3', 'resnet18', pretrained=True)\n",
    "    train_dataset = dataset[\"train\"]\n",
    "    df = get_features_dataset(train_dataset, resnet)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ResNet18 model\n",
    "resnet = torch.hub.load('pytorch/vision:v0.11.3', 'resnet18', pretrained=True)\n",
    "df = extract_features_resnet_threaded_cifar(dataset[\"train\"])\n",
    "\n",
    "# sort the dataframe by index\n",
    "df = df.sort_values(by='Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df[\"Features\"][0]))\n",
    "import pickle\n",
    "with open(f\"{dataset}/dataframe.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{dataset}/dataframe.pkl\", \"rb\") as f:\n",
    "    loaded_df = pickle.load(f)\n",
    "\n",
    "print(type(loaded_df[\"Features\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features DataFrame to a CSV file\n",
    "filename = \"features_cifar_check.csv\"\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "np_array = np.array(df['Features'])\n",
    "flattened_array = np_array.tolist()\n",
    "# Create a DataFrame from the flattened array\n",
    "df = pd.DataFrame(flattened_array)\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('np.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"subset_gen_time.pkl\", \"rb\") as f:\n",
    "    subset_gen_time = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset_gen_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "import pickle\n",
    "import random\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:5\" # change the available gpu number\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"../data\", train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root=\"../data\", train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torch.hub.load('pytorch/vision:v0.11.3', 'resnet101', pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for images, labels in tqdm(train_dataloader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    features = resnet(images)\n",
    "\n",
    "    all_features.append(features)\n",
    "    all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.11.3', 'resnet101', pretrained=True)\n",
    "device_ids = [0, 1, 2, 3]\n",
    "model = model.to(f\"cuda:{device_ids[0]}\")\n",
    "model = nn.DataParallel(model, device_ids=device_ids)\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(train_dataloader):\n",
    "        images = images.to(f\"cuda:{device_ids[0]}\")\n",
    "        labels = labels.to(f\"cuda:{device_ids[0]}\")\n",
    "\n",
    "        features = model(images)\n",
    "\n",
    "        all_features.append(features.cpu())  \n",
    "        all_labels.append(labels.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_features = torch.cat(all_features, dim=0)\n",
    "stacked_labels = torch.cat(all_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_array = list(stacked_features.cpu().detach().numpy())\n",
    "# labels_array = stacked_labels.cpu().detach().numpy()\n",
    "\n",
    "features_array = list(stacked_features.numpy())\n",
    "labels_array = stacked_labels.numpy()\n",
    "\n",
    "df = pd.DataFrame({\"Features\": features_array, \"Label\": labels_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features_array[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./cifar10/dataframe3.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(f\"cifar10/dataframe3.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 5\n",
    "pca = PCA(n_components=n_components)\n",
    "features_matrix = np.stack(data['Features'].values)\n",
    "reduced_features = pca.fit_transform(features_matrix)\n",
    "data['Reduced_Features'] = list(reduced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Features\"\n",
    "\n",
    "groups = data.groupby('Label')\n",
    "dataframes = [group for _, group in groups][5:9]\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "all_samples = pd.concat([df.sample(n) for df in dataframes], ignore_index=True)\n",
    "features = np.stack(all_samples[col].values)\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(features)\n",
    "\n",
    "colors = plt.cm.get_cmap('tab10', len(dataframes))  # Get a colormap with enough colors\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "    start_idx = i * n\n",
    "    end_idx = start_idx + n\n",
    "    ax.scatter(tsne_results[start_idx:end_idx, 0], tsne_results[start_idx:end_idx, 1], color=colors(i), label=f'class {i+1}', s=5)\n",
    "\n",
    "ax.legend()\n",
    "plt.title('t-SNE visualization of multiple DataFrames')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-milo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
